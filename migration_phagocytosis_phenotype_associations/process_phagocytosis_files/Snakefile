#!/usr/bin/env python3
# Snakefile for processing phenotypic assays from phagocytosis pools
# run rename_files.sh first
# snakemake is in /software/teamtrynka/conda/otar2065/bin/snakemake v 7.30.2
import os

POOL=["pool9"]
#POOL=["pool7","pool8","pool11","pool13"]
PHENOTYPE=["phagocytosis"]
# change pool as new data comes from sequencing
SAMPLE,= glob_wildcards("../../../data/crams/pool9/phagocytosis/{sample}_L001.cram")
MERGED,= glob_wildcards("../../../data/crams/pool9/phagocytosis/PhagoAssay8a_{merged}_L001.cram")

rule all:
	input:
		bam=expand("../../../data/bams/{pool}/{phenotype}/{sample}_L002.bam",pool=POOL,phenotype=PHENOTYPE,sample=SAMPLE),
		bam_merged=expand("../../../data/bams/{pool}/{phenotype}/merged_{sample}.bam",pool=POOL,phenotype=PHENOTYPE,sample=SAMPLE),
		another_merged=expand("../../../data/bams/{pool}/{phenotype}/merged/{merged}.bam",pool=POOL,phenotype=PHENOTYPE,merged=MERGED),
		bai_dedup=expand("../../data/bams_nodups/{pool}/{phenotype}/{merged}.bam.bai",pool=POOL,phenotype=PHENOTYPE,merged=MERGED),
		coverage_samtools=expand("../../../data/depth/{merged}_coverage_samtools.txt",merged=MERGED),
		region_list_pool=expand("../../../data/genotypes/{pool}/{phenotype}/{pool}_genotype.txt",pool=POOL, phenotype=PHENOTYPE),
		bam_readcount=expand("../../../data/bam-readcount/{pool}/{phenotype}/{merged}_bam-readcount.txt.gz",pool=POOL,phenotype=PHENOTYPE,merged=MERGED),
		b_estimate=expand("../../../data/b/{pool}/{phenotype}/{merged}_b_estimate.csv",pool=POOL,phenotype=PHENOTYPE,merged=MERGED),
		w_estimate=expand("../../../data/w/{pool}/{phenotype}/{merged}_w_estimate.txt",pool=POOL,phenotype=PHENOTYPE,merged=MERGED)


rule cram_to_bam:
	input:
		cram_l1="../../../data/crams/{pool}/{phenotype}/{sample}_L001.cram",
		cram_l2="../../../data/crams/{pool}/{phenotype}/{sample}_L002.cram"
	output:
		bam_l1="../../../data/bams/{pool}/{phenotype}/{sample}_L001.bam",
		bam_l2="../../../data/bams/{pool}/{phenotype}/{sample}_L002.bam"
	message: "Cram to bam."
	params:
		group="-G teamtrynka",
		queue="-q normal",
		threads="-n 32",
		memory="-M100000 -R'span[hosts=1] select[mem>100000] rusage[mem=100000]'",
		jobname= "-o ../../../logs/log_cram_to_bam.{sample}.%J.%I",
		error="-e ../../../errors/error_cram_to_bam.{sample}.%J.%I",
		reference="/lustre/scratch125/core/sciops_repository/references/Homo_sapiens/GRCh38_15_plus_hs38d1/all/fasta/Homo_sapiens.GRCh38_15_plus_hs38d1.fa"
	shell:
	 	"""
		set +o pipefail;
		mkdir -p ../../../data/bams
		/software/sciops/pkgg/samtools/1.14.0/bin/samtools view -bh -q 40 -T {params.reference} -o {output.bam_l1} {input.cram_l1}
		/software/sciops/pkgg/samtools/1.14.0/bin/samtools view -bh -q 40 -T {params.reference} -o {output.bam_l2} {input.cram_l2}

		"""
rule merge_lanes:
    input:
        bam_l1="../../../data/bams/{pool}/{phenotype}/{sample}_L001.bam",
        bam_l2="../../../data/bams/{pool}/{phenotype}/{sample}_L002.bam"
    output:
        bam="../../../data/bams/{pool}/{phenotype}/merged_{sample}.bam"
    message: "Merging lanes."
    params:
        group="-G teamtrynka",
        queue="-q normal",
        threads="-n 16",
        memory="-M100000 -R'span[hosts=1] select[mem>100000] rusage[mem=100000]'",
        jobname= "-o ../../../logs/log_merge_lanes.{sample}.%J.%I",
        error="-e ../../../errors/error_merge_lanes.{sample}.%J.%I",
        samtools_threads=16
    shell:
        """
        set +o pipefail;

        /software/teamtrynka/conda/trynka-base/bin/samtools merge \
        --threads {params.samtools_threads} \
        ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/{wildcards.sample}_tmp.bam {input.bam_l1} {input.bam_l2}

        /software/teamtrynka/conda/trynka-base/bin/samtools sort \
        --threads {params.samtools_threads} \
        -o {output.bam} ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/{wildcards.sample}_tmp.bam

        rm ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/{wildcards.sample}_tmp.bam

        """
rule merge_samples:
    input:
        bam1="../../../data/bams/{pool}/{phenotype}/merged_PhagoAssay8a_{merged}.bam",
		bam2="../../../data/bams/{pool}/{phenotype}/merged_PhagoAssay8b_{merged}.bam"
    output:
		bam="../../../data/bams/{pool}/{phenotype}/merged/{merged}.bam"
    message: "Merging samples."
    params:
        group="-G teamtrynka",
        queue="-q normal",
        threads="-n 16",
        memory="-M100000 -R'span[hosts=1] select[mem>100000] rusage[mem=100000]'",
        jobname= "-o ../../../logs/log_merge_samples.{merged}.%J.%I",
        error="-e ../../../errors/error_merge_samples.{merged}.%J.%I",
        samtools_threads=16
    shell:
        """
        set +o pipefail;

        /software/teamtrynka/conda/trynka-base/bin/samtools merge \
        --threads {params.samtools_threads} \
        ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}_tmp.bam {input.bam1} {input.bam2}

        /software/teamtrynka/conda/trynka-base/bin/samtools sort \
        --threads {params.samtools_threads} \
        -o {output.bam} ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}_tmp.bam

        rm ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}_tmp.bam 

        """

rule subset_and_index_bam:
	input: rules.merge_samples.output
	output:
		bai="../../../data/bams/{pool}/{phenotype}/merged/{merged}.bam.bai"
	message: "Indexing bams."
	params:
		group="-G teamtrynka",
		queue="-q normal",
		threads="-n 32",
		memory="-M20000 -R'span[hosts=1] select[mem>20000] rusage[mem=20000]'",
		jobname= "-o ../../../logs/log_subset_and_index_bam.{merged}.%J.%I",
		error="-e ../../../errors/error_subset_and_index_bam.{merged}.%J.%I"
	shell:
	 	"""
		set +o pipefail;
		/software/teamtrynka/conda/trynka-base/bin/samtools index -@ 32 ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}.bam
        /software/teamtrynka/conda/trynka-base/bin/samtools view -@ 32 -b ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}.bam chr{{1..22}} chrX > ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}_temp.bam
        mv ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}_temp.bam ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}.bam
		/software/teamtrynka/conda/trynka-base/bin/samtools index -@ 32 ../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}.bam {output.bai}

		"""

rule remove_dups_sort_bam:
    input: rules.subset_and_index_bam.output
    output:
        bam="../../../data/bams_nodups/{pool}/{phenotype}/{merged}.bam",
        bai="../../../data/bams_nodups/{pool}/{phenotype}/{merged}.bam.bai"
    message: "Remove duplicates with picard, and sort."
    params:
        group="-G teamtrynka",
        queue="-q normal",
        threads="-n 64",
        memory="-M100000 -R'span[hosts=1] select[mem>100000] rusage[mem=100000]'",
        jobname= "-o ../../../logs/log_remove_dups_sort_bam.{merged}.%J.%I",
        error="-e ../../../errors/error_remove_dups_sort_bam.{merged}.%J.%I"
    shell:
        """
        set +o pipefail;

        java -jar /software/teamtrynka/picard.jar MarkDuplicates \
        I=../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/merged/{wildcards.merged}.bam \
        O=../../../data/bams_nodups/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_nodups_unsorted.bam \
        M=../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_marked_dup_metrics.txt \
        REMOVE_DUPLICATES=true

        /software/teamtrynka/conda/trynka-base/bin/samtools sort -@ 64 -o {output.bam} ../../../data/bams_nodups/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_nodups_unsorted.bam
        rm ../../../data/bams_nodups/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_nodups_unsorted.bam
		/software/teamtrynka/conda/trynka-base/bin/samtools index -@ 64 {output.bam} {output.bai}

		"""

rule get_coverage:
	input:rules.remove_dups_sort_bam.output
	output:
		coverage="../../../data/depth/{pool}/{phenotype}/nodups/{merged}_coverage.txt",
		coverage_samtools="../../../data/depth/{pool}/{phenotype}/nodups/{merged}_coverage_samtools.txt"
	message: "Calculating depth and coverage from crams."
	params:
		group="-G teamtrynka",
		queue="-q normal",
		threads="-n 32",
		memory="-M100000 -R'span[hosts=1] select[mem>100000] rusage[mem=100000]'",
		jobname= "-o ../../../logs/log_get_coverage.{merged}.%J.%I",
		error="-e ../../../errors/error_get_coverage.{merged}.%J.%I"
	shell:
		"""
        set +o pipefail;

		mkdir -p ../../../data/depth
		depth=$(/software/teamtrynka/conda/trynka-base/bin/samtools depth -a "../../../data/bams/{wildcards.pool}/{wildcards.phenotype}/nodups/{wildcards.merged}.bam"  |  awk '{{sum+=$3}} END {{ print sum/NR}}' )
		echo $depth > {output.coverage}
		/software/sciops/pkgg/samtools/1.14.0/bin/samtools coverage -d 0 -o {output.coverage_samtools} {input.bam}
		"""

rule get_region_list:
	input:
		genotype_pool="../../../data/genotypes/{pool}/{phenotype}/{pool}_genotype.vcf.gz"
	output:
		region_list_pool="../../../data/genotypes/{pool}/{phenotype}/{pool}_genotype.txt",
	message: "Getting region list for bam-readcount."
	params:
		group="-G teamtrynka",
		queue="-q normal",
		threads="-n 2",
		memory="-M40000 -R'span[hosts=1] select[mem>40000] rusage[mem=40000]'",
		jobname= "-o ../../../logs/log_get_region_list.%J.%I",
		error="-e ../../../errors/error_get_region_list.%J.%I"
	shell:
	 	"""
		/software/teamtrynka/conda/otar2065/bin/Rscript 1.Create_region_list_bam-readcount.R {input.genotype_pool} {output.region_list_pool}
		"""

rule count_alleles:
	input:
		region_list_pool="../../../data/genotypes/{pool}/{phenotype}/{pool}_genotype.txt",
		bam="../../../data/bams_nodups/{pool}/{phenotype}/{merged}.bam",
		bai="../../../data/bams_nodups/{pool}/{phenotype}/{merged}.bam.bai"
	output:
		bam_readcount="../../../data/bam-readcount/{pool}/{phenotype}/{merged}_bam-readcount.txt.gz"
	message: "Counting alleles with bam-readcount."
	params:
		group="-G teamtrynka",
		queue="-q normal",
		threads="-n 6",
		memory="-M60000 -R'span[hosts=1] select[mem>60000] rusage[mem=60000]'",
		jobname= "-o ../../../logs/log_count_alleles.{merged}.%J.%I",
		error="-e ../../../errors/error_count_alleles.{merged}.%J.%I",
		depth="1000000000",
		read_quality="30",
		reference="/lustre/scratch125/core/sciops_repository/references/Homo_sapiens/GRCh38_15_plus_hs38d1/all/fasta/Homo_sapiens.GRCh38_15_plus_hs38d1.fa"
	shell:
		"""
		/software/teamtrynka/bam-readcount/bin/bam-readcount -w 1 \
		-d {params.depth} -q {params.read_quality} -f {params.reference} \
		-l {input.region_list_pool} {input.bam} > ../../../data/bam-readcount/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_bam-readcount_tmp.txt

		# filter to remove positions that have 0 coverage
		awk -F'\t' 'NR == 1 || $4 != 0' ../../../data/bam-readcount/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_bam-readcount_tmp.txt > ../../../data/bam-readcount/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_bam-readcount.txt
		gzip ../../../data/bam-readcount/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_bam-readcount.txt
		rm ../../../data/bam-readcount/{wildcards.pool}/{wildcards.phenotype}/{wildcards.merged}_bam-readcount_tmp.txt

		"""

rule calculate_b_estimate_MAD:
	input:
		bam_readcount="../../../data/bam-readcount/{pool}/{phenotype}/{merged}_bam-readcount.txt.gz",
		genotype_pool="../../../data/genotypes/{pool}/{phenotype}/{pool}_genotype.vcf.gz"
	output:
		b_estimate="../../../data/b/{pool}/{phenotype}/{merged}_b_estimate.csv",
		genotype_minor_allele_dosage="../../../data/genotypes/{pool}/{phenotype}/{merged}_genotype_minor_allele_dosage.csv",
		variants_retained="../../../data/genotypes/{pool}/{phenotype}/{merged}_Nvariants_retained_reduced_genotype.txt"
	message: "Transforming bam-readcount output to MAF estimate (b_estimate) and VCF to minor allele dosage."
	params:
		group="-G teamtrynka",
		queue="-q normal",
		threads="-n 32",
		memory="-M50000 -R'span[hosts=1] select[mem>50000] rusage[mem=50000]'",
		jobname= "-o ../../../logs/log_calculate_b_estimate.{merged}.%J.%I",
		error="-e ../../../errors/error_calculate_b_estimate.{merged}.%J.%I"
	shell:
		"""
			/software/teamtrynka/conda/otar2065/bin/Rscript 2.Bam-readcount_to_MAF_estimate.R \
			{input.bam_readcount} {input.genotype_pool} \
			{output.b_estimate} {output.genotype_minor_allele_dosage} {output.variants_retained}
		"""

rule estimate_weights:
	input:
		b_estimate="../../../data/b/{pool}/{phenotype}/{merged}_b_estimate.csv",
		genotype_minor_allele_dosage="../../../data/genotypes/{pool}/{phenotype}/{merged}_genotype_minor_allele_dosage.csv"
	output:
		w_estimate="../../../data/w/{pool}/{phenotype}/{merged}_w_estimate.txt"
	message: "Estimate proportion (weights) of donors."
	params:
		group="-G teamtrynka",
		queue="-q normal",
		threads="-n 32",
		memory="-M50000 -R'span[hosts=1] select[mem>50000] rusage[mem=50000]'",
		jobname= "-o ../../../logs/log_estimate_weights.{merged}.%J.%I",
		error="-e ../../../errors/error_estimate_weights.{merged}.%J.%I"
	shell:
	 	"""
		mkdir -p ../../../data/w
		/software/teamtrynka/conda/otar2065/bin/Rscript 3.estimate_weights.R \
		{input.b_estimate} {input.genotype_minor_allele_dosage} \
		{output.w_estimate}
		"""
